{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('meinian_round1_train_20180408.csv',sep=',',encoding='gbk')\n",
    "test=pd.read_csv('meinian_round1_test_b_20180505.csv',sep=',',encoding='gbk')\n",
    "data_part1 = pd.read_csv(\"meinian_round1_data_part1_20180408.txt\", sep=\"$\")\n",
    "data_part2 =pd.read_csv(\"meinian_round1_data_part2_20180408.txt\", sep='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.shape[0]*(test.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=pd.read_csv(\"meinian4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.shape[0]*(result.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(test[\"vid\"]==result[\"vid\"]).sum()*(result.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_part1和data_part2进行合并\n",
    "part1_2 = pd.concat([data_part1,data_part2],axis=0)#{0/'index', 1/'columns'}, default 0\n",
    "part1_2 = pd.DataFrame(part1_2).sort_values('vid').reset_index(drop=True)\n",
    "#vid_set dataframe vid 病人集合 dataframe\n",
    "vid_set=pd.concat([train['vid'],test['vid']],axis=0)\n",
    "vid_set=pd.DataFrame(vid_set).sort_values('vid').reset_index(drop=True)\n",
    "#并剔除掉与train、test不相关vid所在的数据行\n",
    "part1_2=part1_2[part1_2['vid'].isin(vid_set['vid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6750883, 3)\n",
      "                                vid table_id  0\n",
      "0  000330ad1f424114719b7525f400660b     0101  1\n",
      "1  000330ad1f424114719b7525f400660b     0102  3\n",
      "2  000330ad1f424114719b7525f400660b     0113  1\n",
      "3  000330ad1f424114719b7525f400660b     0114  1\n",
      "4  000330ad1f424114719b7525f400660b     0115  1\n",
      "(6515933, 3)\n"
     ]
    }
   ],
   "source": [
    "print(part1_2.shape)\n",
    "vid_tabid_group = part1_2.groupby(['vid','table_id']).size().reset_index()\n",
    "vid_tabid_group = part1_2.groupby(['vid','table_id']).size().reset_index()\n",
    "print(vid_tabid_group.head())\n",
    "print(vid_tabid_group.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      000330ad1f424114719b7525f400660b_0102\n",
      "147    0003848ebd8d8163603760d53d975693_0101\n",
      "148    0003848ebd8d8163603760d53d975693_0102\n",
      "228    0003848ebd8d8163603760d53d975693_1308\n",
      "299    000401cbf304d5a8bd862a81bacfa494_0101\n",
      "Name: new_index, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 重塑index用来去重,区分重复部分和唯一部分\n",
    "vid_tabid_group['new_index'] = vid_tabid_group['vid'] + '_' + vid_tabid_group['table_id']\n",
    "#vid_tabid_group_dup 重复的vid_tabid 检查项\n",
    "vid_tabid_group_dup = vid_tabid_group[vid_tabid_group[0]>1]['new_index']\n",
    "print(vid_tabid_group_dup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_2['new_index'] = part1_2['vid'] + '_' + part1_2['table_id']\n",
    "dup_part = part1_2[part1_2['new_index'].isin(list(vid_tabid_group_dup))]\n",
    "dup_part = dup_part.sort_values(['vid','table_id'])\n",
    "unique_part = part1_2[~part1_2['new_index'].isin(list(vid_tabid_group_dup))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重复数据的拼接操作\n",
    "# 将vid_tabid 相同行 拼接\n",
    "def merge_table(df):\n",
    "    df['field_results'] = df['field_results'].astype(str)\n",
    "    if df.shape[0] > 1:\n",
    "        merge_df = \" \".join(list(df['field_results']))\n",
    "    else:\n",
    "        merge_df = df['field_results'].values[0]\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "part1_2_dup = dup_part.groupby(['vid','table_id']).apply(merge_table).reset_index()\n",
    "part1_2_dup.rename(columns={0:'field_results'},inplace=True)\n",
    "# 重复数据处理后 数据\n",
    "part1_2_res = pd.concat([part1_2_dup,unique_part[['vid','table_id','field_results']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id_group=part1_2.groupby('table_id').size().sort_values(ascending=False)\n",
    "table_id_group.to_csv('part_tabid_size.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47731, 2736)\n"
     ]
    }
   ],
   "source": [
    "# 行列转换 重新组织index vid 和columns  table_id\n",
    "merge_part1_2 = part1_2_res.pivot(index='vid',values='field_results',columns='table_id')\n",
    "print(merge_part1_2.shape)\n",
    "merge_part1_2.to_csv('merge_part1_2.csv',encoding='utf-8')\n",
    "#print(merge_part1_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 删除掉一些出现次数低，缺失比例大的字段，保留超过阈值的特征\n",
    "def remain_feat(df,thresh=0.9):\n",
    "    \"\"\"\n",
    "    删除掉一些出现次数低，缺失比例大的字段，保留超过阈值的特征,返回 需要保存的特征的list\n",
    "    \"\"\"\n",
    "    exclude_feats = []\n",
    "    print('----------移除数据缺失多的字段-----------')\n",
    "    print('移除之前总的字段数量',len(df.columns))\n",
    "    num_rows = df.shape[0]\n",
    "    for c in df.columns:\n",
    "        num_missing = df[c].isnull().sum()\n",
    "        if num_missing == 0:\n",
    "            continue\n",
    "        missing_percent = num_missing / float(num_rows)\n",
    "        if missing_percent > thresh:\n",
    "            exclude_feats.append(c)\n",
    "    print(\"移除缺失数据的字段数量: %s\" % len(exclude_feats))\n",
    "    # 保留超过阈值的特征\n",
    "    feats = []\n",
    "    for c in df.columns:\n",
    "        if c not in exclude_feats:\n",
    "            feats.append(c)\n",
    "    print('剩余的字段数量',len(feats))\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------移除数据缺失多的字段-----------\n",
      "移除之前总的字段数量 2736\n",
      "移除缺失数据的字段数量: 2334\n",
      "剩余的字段数量 402\n"
     ]
    }
   ],
   "source": [
    "feats=remain_feat(merge_part1_2,thresh=0.96)\n",
    "merge_part1_2=merge_part1_2[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_part1_2.to_csv('merge_part1_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['004997', '0101', '0102', '0104', '0105', '0106', '0107', '0108',\n",
       "       '0109', '0113',\n",
       "       ...\n",
       "       '979027', 'A201', 'A202', 'A301', 'A302', 'A601', 'A701', 'A703',\n",
       "       'A705', 'vid'],\n",
       "      dtype='object', name='table_id', length=403)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_part1_2[\"vid\"]=merge_part1_2.index\n",
    "merge_part1_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集 测试机 并且 同5个指标拼接\n",
    "train_of_part=merge_part1_2[merge_part1_2['vid'].isin(train['vid'])]\n",
    "test_of_part=merge_part1_2[merge_part1_2['vid'].isin(test['vid'])]\n",
    "\n",
    "train=pd.merge(train,train_of_part,on='vid')\n",
    "test=pd.merge(test,test_of_part,on='vid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vid', '收缩压', '舒张压', '血清甘油三酯', '血清高密度脂蛋白', '血清低密度脂蛋白', '004997', '0101',\n",
       "       '0102', '0104',\n",
       "       ...\n",
       "       '979026', '979027', 'A201', 'A202', 'A301', 'A302', 'A601', 'A701',\n",
       "       'A703', 'A705'],\n",
       "      dtype='object', length=408)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗训练集中的五个指标\n",
    "def clean_label(x):\n",
    "    x=str(x)\n",
    "    if '+' in x:#16.04++\n",
    "        i=x.index('+')\n",
    "        x=x[0:i]\n",
    "    if '>' in x:#> 11.00\n",
    "        i=x.index('>')\n",
    "        x=x[i+1:]\n",
    "    if len(x.split(sep='.'))>2:#2.2.8\n",
    "        i=x.rindex('.')\n",
    "        x=x[0:i]+x[i+1:]\n",
    "    if '未做' in x or '未查' in x or '弃查' in x:\n",
    "        x=np.nan\n",
    "    if str(x).isdigit()==False and len(str(x))>4:\n",
    "        x=x[0:4]\n",
    "        pass\n",
    "    x=float(x)\n",
    "    if x>900:\n",
    "        x=np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=['收缩压', '舒张压', '血清甘油三酯', '血清高密度脂蛋白', '血清低密度脂蛋白']\n",
    "for c in targets:\n",
    "    train[c]=train[c].apply(clean_label)\n",
    "    train[c]=train[c].astype('float64')    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>收缩压</th>\n",
       "      <th>舒张压</th>\n",
       "      <th>血清甘油三酯</th>\n",
       "      <th>血清高密度脂蛋白</th>\n",
       "      <th>血清低密度脂蛋白</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38192.000000</td>\n",
       "      <td>38190.000000</td>\n",
       "      <td>38199.000000</td>\n",
       "      <td>38199.000000</td>\n",
       "      <td>38199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.049618</td>\n",
       "      <td>76.998115</td>\n",
       "      <td>1.616563</td>\n",
       "      <td>1.406683</td>\n",
       "      <td>2.769720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.275625</td>\n",
       "      <td>12.580344</td>\n",
       "      <td>1.344201</td>\n",
       "      <td>0.341184</td>\n",
       "      <td>0.852187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>-1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>1.910000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>252.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                收缩压           舒张压        血清甘油三酯      血清高密度脂蛋白      血清低密度脂蛋白\n",
       "count  38192.000000  38190.000000  38199.000000  38199.000000  38199.000000\n",
       "mean     126.049618     76.998115      1.616563      1.406683      2.769720\n",
       "std       19.275625     12.580344      1.344201      0.341184      0.852187\n",
       "min        0.000000      0.000000      0.100000      0.150000     -1.200000\n",
       "25%      112.000000     68.000000      0.880000      1.160000      2.180000\n",
       "50%      124.000000     76.000000      1.270000      1.350000      2.690000\n",
       "75%      137.000000     85.000000      1.910000      1.600000      3.260000\n",
       "max      252.000000    148.000000     28.800000      4.780000     11.500000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[targets].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存train_set和test_set\n",
    "train.to_csv('train_set.csv',index=False,encoding='utf-8')\n",
    "test.to_csv('test_set.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
